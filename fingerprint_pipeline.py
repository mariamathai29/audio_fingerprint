# -*- coding: utf-8 -*-
"""audio

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WDfC1g7T_lPQ6D0tlAIC32LJTXuRaLl2
"""

# install requirements

!pip install numpy scipy librosa matplotlib bitarray

from bitarray import bitarray
import librosa
import numpy as np

# plot waveforms

y, sr = librosa.load('/content/drive/MyDrive/songs/Born_To_Die.wav', sr=5000, mono=True)

#y, sr = librosa.load('/content/drive/MyDrive/btdcomp.mp3', sr=5000, mono=True)

import matplotlib.pyplot as plt
import numpy as np

plt.plot(y[:500])
plt.title("Waveform (first 500 samples)")
plt.show()

frame = y[0:2048]
fft = np.abs(np.fft.rfft(frame * np.hanning(len(frame))))
plt.plot(fft)
plt.title("FFT Magnitude")
plt.show()

# build audio sub-fingerprints

frame_size = 1850
hop_size = 58
window = np.hanning(frame_size)

frames = []
for i in range(0, len(y) - frame_size, hop_size):
    frames.append(y[i:i+frame_size] * window)
spectra = [np.abs(np.fft.rfft(frame))**2 for frame in frames]

def hz_to_bin(freq):
    return int(freq * frame_size / 5000)

edges = np.logspace(np.log10(300), np.log10(2000), num=34)
bands = [(hz_to_bin(edges[i]), hz_to_bin(edges[i+1])) for i in range(33)]

band_energies = []
for spectrum in spectra:
    energies = [np.sum(spectrum[start:end]) for (start, end) in bands]
    band_energies.append(energies)

sub_fingerprints = []
for n in range(1, len(band_energies)):
    sub = []
    for m in range(1, 33):
        e1 = band_energies[n-1][m-1] + band_energies[n][m]
        e2 = band_energies[n-1][m] + band_energies[n][m-1]
        bit = 1 if e1 > e2 else 0
        sub.append(bit)
    sub_fingerprints.append(sub)

# step 2 check

print(f"generated {len(sub_fingerprints)} subfingerprints.")
print(f"first subfingerprint: {sub_fingerprints[0]}")

# aggregate sub-fingerprints
fingerprint_blocks = []
for i in range(len(sub_fingerprints) - 255):
    block = sub_fingerprints[i:i+256]
    fingerprint_blocks.append(block)

from bitarray import bitarray

bit_blocks = []
for block in fingerprint_blocks:
    ba = bitarray()
    for row in block:
        ba.extend(row)
    bit_blocks.append(ba)

# step3 validate

print(len(bit_blocks))             # no. of 3s blocks
print(len(bit_blocks[0]))         # expected to be 8192
print(bit_blocks[0].count(1))     # number of ones in first block
print(bit_blocks[0].to01()[:64])  # view first 64 bits as string

def plot_comparison(original, compressed):
    import matplotlib.pyplot as plt
    import numpy as np

# convert to matrices
    def to_matrix(bit_block):
        bits = bit_block.to01()
        return np.array([int(b) for b in bits]).reshape((256, 32))

    mat1 = to_matrix(original)
    mat2 = to_matrix(compressed)
    bit_error = (mat1 != mat2).astype(int)

# plot
    fig, axs = plt.subplots(1, 3, figsize=(10, 8))

    titles = ['Original', 'Compressed (mp3)', 'Bit Errors']
    data = [mat1, mat2, bit_error]
    cmaps = ['gray_r', 'gray_r', 'gray_r']

    for ax, title, mat, cmap in zip(axs, titles, data, cmaps):
        ax.imshow(mat, cmap=cmap, interpolation='nearest', aspect='auto')
        ax.set_title(title)
        ax.set_xticks([0, 31])
        ax.set_xticklabels(["B31", "B0"])
        ax.set_yticks([0, 255])
        ax.set_yticklabels(["0", "256"])
        ax.set_xlabel("Bits")
        ax.set_ylabel("Time (Frames)")

    plt.tight_layout()
    plt.show()

# also print bit error rate
    total_bits = 256 * 32
    errors = np.sum(bit_error)
    ber = errors / total_bits
    print(f"Bit Error Rate (BER): {ber:.3f}")

# build fingerprinting pipeline

def get_bit_blocks(filepath, sr=5000):

    y, _sr = librosa.load(filepath, sr=sr, mono=True)

# frame segmentation
    frame_size = 1850
    hop_size = 58
    window = np.hanning(frame_size)

    frames = []
    for i in range(0, len(y) - frame_size, hop_size):
        frames.append(y[i:i+frame_size] * window)
    spectra = [np.abs(np.fft.rfft(frame))**2 for frame in frames]

# bands
    def hz_to_bin(freq):
        return int(freq * frame_size / sr)

    edges = np.logspace(np.log10(300), np.log10(2000), num=34)
    bands = [(hz_to_bin(edges[i]), hz_to_bin(edges[i+1])) for i in range(33)]

# sub-fingerprints
    band_energies = []
    for spectrum in spectra:
        energies = [np.sum(spectrum[start:end]) for (start, end) in bands]
        band_energies.append(energies)

    sub_fingerprints = []
    for n in range(1, len(band_energies)):
        sub = []
        for m in range(1, 33):
            e1 = band_energies[n-1][m-1] + band_energies[n][m]
            e2 = band_energies[n-1][m] + band_energies[n][m-1]
            bit = 1 if e1 > e2 else 0
            sub.append(bit)
        sub_fingerprints.append(sub)

# fingerprint blocks
    fingerprint_blocks = []
    for i in range(len(sub_fingerprints) - 255):
        block = sub_fingerprints[i:i+256]
        fingerprint_blocks.append(block)

    bit_blocks = []
    for block in fingerprint_blocks:
        ba = bitarray()
        for row in block:
            ba.extend(row)
        bit_blocks.append(ba)

    return bit_blocks

# compare bit blocks

bit_blocks_wav = get_bit_blocks("/content/drive/MyDrive/songs/BelAir.wav")
bit_blocks_mp3 = get_bit_blocks("/content/drive/MyDrive/belair_comp.mp3")

plot_comparison(bit_blocks_wav[0], bit_blocks_mp3[0])

import os
# build database
def build_fingerprint_database(audio_dir, sr=5000):

    supported_exts = ['.mp3', '.wav', '.flac']
    database = {}

    for fname in os.listdir(audio_dir):
        if not any(fname.lower().endswith(ext) for ext in supported_exts):
            continue

        track_id = os.path.splitext(fname)[0]
        filepath = os.path.join(audio_dir, fname)

        try:
            blocks = get_bit_blocks(filepath, sr=sr)
            database[track_id] = blocks
            print(f"Processed: {fname}, blocks: {len(blocks)}")
        except Exception as e:
            print(f"Error processing {fname}: {e}")

    return database

audio_dir = "/content/drive/MyDrive/songs"
fingerprint_db = build_fingerprint_database(audio_dir)

# hamming distance and matching
def hamming_distance(b1: bitarray, b2: bitarray) -> int:
    return (b1 ^ b2).count()

from collections import defaultdict, Counter

def match_with_offsets(query_blocks, database, threshold=256):

    offset_votes = defaultdict(list)

    for q_idx, qblock in enumerate(query_blocks):
        for track_id, db_blocks in database.items():
            for db_idx, db_block in enumerate(db_blocks):
                if hamming_distance(qblock, db_block) <= threshold:
                    offset = db_idx - q_idx
                    offset_votes[track_id].append(offset)
                    break

    match_summary = []
    for track_id, offsets in offset_votes.items():
        if offsets:
            most_common_offset, count = Counter(offsets).most_common(1)[0]
            match_summary.append({
                "track": track_id,
                "matches": len(offsets),
                "estimated_offset_blocks": most_common_offset,
                "estimated_offset_sec": most_common_offset * 58 / 5000  # 58-hop at 5kHz
            })

# sort by number of matching blocks
    match_summary.sort(key=lambda x: x["matches"], reverse=True)
    return match_summary

import soundfile as sf

def get_query_clip(filepath, start_sec=30, duration_sec=10, sr=5000):
    y, _ = librosa.load(filepath, sr=sr, mono=True, offset=start_sec, duration=duration_sec)
    sf.write("query_clip.wav", y, sr)
    return get_bit_blocks("query_clip.wav", sr=sr)

query_blocks = get_query_clip("/content/drive/MyDrive/belair_comp.mp3", start_sec=60, duration_sec=10)
results = match_with_offsets(query_blocks, fingerprint_db, threshold=256)

for r in results:
    print(f"{r['track']}: {r['matches']} matches")
    print(f"Estimated offset: {r['estimated_offset_blocks']} blocks â‰ˆ {r['estimated_offset_sec']:.2f} sec\n")

results = match_with_offsets(query_blocks, fingerprint_db, threshold=1638)

if results:
    best_match = results[0]  # top hit
    print("best match!")
    print(f"song: {best_match['track']}")
    print(f"matches: {best_match['matches']}")
    print(f"offset: {best_match['estimated_offset_sec']:.2f} seconds")
else:
    print("no matching song found.")